In this project, a VGG16-based transfer learning model was developed to classify iris images as Healthy or Unhealthy. The model achieved a high accuracy of 96% on the test set, with strong precision and recall for both classes, demonstrating effective learning despite the small dataset. Grad-CAM visualizations highlighted the iris regions that contributed most to the modelâ€™s predictions, providing interpretability and transparency. For future improvements, the model can be enhanced by using a larger and more diverse dataset, experimenting with advanced architectures like EfficientNet, and incorporating automated preprocessing to handle varied lighting and occlusions in real-world iris images.
